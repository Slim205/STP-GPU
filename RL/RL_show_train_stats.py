import os
import sys
os.environ["TOKENIZERS_PARALLELISM"] = "false"
from collections import defaultdict
import argparse
import logging
import numpy as np
from tqdm.auto import tqdm
from datetime import datetime
from copy import deepcopy
from typing import Any, Dict, List, Tuple, Optional

from utils.model_utils import get_lemma_key, insert_lemma
from utils.gcloud_utils import read_file, path_exists
from utils.RL_utils import load_ds_from_config

BATCH_SIZE = 2048

if __name__ == "__main__":
    logging.basicConfig(format='[%(asctime)s - %(name)s - %(levelname)s] %(message)s', level=logging.INFO, force=True)
    parser = argparse.ArgumentParser()
    parser.add_argument("--exp_dir", type=str, default=None)
    parser.add_argument("--dataset_config", type=str, default=None)
    parser.add_argument("--init_sampler_dir", type=str, default=None)
    args = parser.parse_args()
    print(args)

    if args.init_sampler_dir is not None:
        logging.info(f'Loading proofs from {args.init_sampler_dir}')
        sampler_dict = read_file(args.init_sampler_dir)
        assert sampler_dict is not None, f"Failed to read {args.init_sampler_dir}"
        lemma_mapping = sampler_dict['lemma_mapping']
        succ_lemmas = sampler_dict['succ_lemmas']
        del sampler_dict
    else:
        lemma_mapping = {}
        succ_lemmas = set()

    formatted_ds = load_ds_from_config(args.dataset_config)

    for round in tqdm(range(100)):
        if not path_exists(f'{args.exp_dir}/round{round}/generated_proofs.json.gz'):
            break
        logging.info(f"Working on {args.exp_dir}/round{round}")
        generated_proofs = read_file(f'{args.exp_dir}/round{round}/sampler_ckpt/generated_proofs.json')
        assert generated_proofs is not None, f"Failed to read {args.exp_dir}/round{round}/sampler_ckpt"
        round_path = os.path.join(args.exp_dir, f'round{round}')

        for test_info in generated_proofs:
            insert_lemma(lemma_mapping, test_info)

        relevant_lemmas = set()
        for test_info in formatted_ds:
            relevant_lemmas.add(lemma_mapping[get_lemma_key(test_info)])
        print(len(relevant_lemmas))
        # update_succ_lemmas(generated_proofs, lemma_mapping, succ_lemmas)
        for test_info in generated_proofs:
            key = get_lemma_key(test_info)
            if test_info.get('complete', False) and (key in lemma_mapping):
                succ_lemmas.add(lemma_mapping[key])

        succ_rate = len(succ_lemmas.intersection(relevant_lemmas)) / len(relevant_lemmas)
        print('=' * 10 + f' Round {round} ' + '=' * 10)
        print(f'Cumulative succ rate = {succ_rate * 100:.3f}')
        print(f'Number of generated proofs = ', len(generated_proofs))

        # count the number of correct proofs
        get_key = lambda test_info: tuple(set(test_info['label']))
        proof_counts = defaultdict(int)
        for test_info in generated_proofs:
            if test_info.get('complete', False):
                proof_counts[get_key(test_info)] += 1
        # print proof counts in a pretty way
        proof_counts = sorted(proof_counts.items(), key=lambda x: x[1], reverse=True)
        print('Proof counts:')
        for proof, count in proof_counts:
            print(f'{proof}: {count}')

        # number of proofs with conjecture in the label
        conjecture_proofs = sum(any(label.startswith('conjecture') for label in test_info['label']) for test_info in generated_proofs if test_info.get('result', 0) > 0)
        original_proofs = sum(not any(label.startswith('conjecture') for label in test_info['label']) for test_info in generated_proofs if test_info.get('result', 0) > 0)
        print(f'Correct proofs to theorems generated by conjecture model: {conjecture_proofs}')
        print(f'Correct proofs to original theorems: {original_proofs}')